{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: getting started with Delight\n",
    "\n",
    "- last verification date : 2024-10-24 (Sylvie dagoret-Campagne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steering of the code is performed through a parameter file.\n",
    "We will use the parameter file \"tests_nb/parametersTest.cfg\".\n",
    "- This file contains a description of the bands and data to be used.\n",
    "- In this example we will generate mock data for the ugriz SDSS bands,\n",
    "- Fit each object with our GP using ugi bands only and see how it predicts the rz bands.\n",
    "- This is an example for filling in/predicting missing bands in a fully bayesian way with a flexible SED model quickly via our photo-z GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../..')\n",
    "from delight.io import *\n",
    "from delight.utils import *\n",
    "from delight.photoz_gp import PhotozGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying were are the data file used for input outout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of the config parameter file\n",
    "param_path = \"tests_nb\"\n",
    "# path where the input fluxes file are generated including the Kerenl gaussian process file generated\n",
    "data_path = \"data_nb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "if not os.path.exists(param_path):\n",
    "    os.mkdir(param_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the execution is performed in this folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the parameter file\n",
    "Let's create a parameter file from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile_txt = \"\"\"\n",
    "# DELIGHT parameter file\n",
    "# Syntactic rules:\n",
    "# - You can set parameters with : or =\n",
    "# - Lines starting with # or ; will be ignored\n",
    "# - Multiple values (band names, band orders, confidence levels)\n",
    "#   must beb separated by spaces\n",
    "# - The input files should contain numbers separated with spaces.\n",
    "# - underscores mean unused column\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Specifying the Filters used for the photometric survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's describe the bands we will use. This must be a superset (ideally the union) of all the bands involved in the training and target sets, including cross-validation. \n",
    "- Each band should have its own file, containing a tabulated version of the filter response.\n",
    "See example files shipped with the code for formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "paramfile_txt += \"\"\"\n",
    "[Bands]\n",
    "names: U_SDSS G_SDSS R_SDSS I_SDSS Z_SDSS\n",
    "directory: ../../data/FILTERS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the SED templates used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now describe the system of SED templates to use (needed for the mean fct of the GP, for simulating objects, and for the template fitting routines).\n",
    "\n",
    "- Each template should have its own file (see shipped files for formatting example). \n",
    "- lambdaRef will be the pivot wavelenght used for normalizing the templates.\n",
    "- p_z_t and p_t containts parameters for the priors of each template, for $p(z|t) p(t)$. \n",
    "- Calibrating those numbers will be the topic of another tutorial.\n",
    "\n",
    "By default the set of templates and the prior calibration can be left untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile_txt += \"\"\"\n",
    "[Templates]\n",
    "directory: ../../data/CWW_SEDs\n",
    "names: El_B2004a Sbc_B2004a Scd_B2004a SB3_B2004a SB2_B2004a Im_B2004a ssp_25Myr_z008 ssp_5Myr_z008\n",
    "p_t: 0.27 0.26 0.25 0.069 0.021 0.11 0.0061 0.0079\n",
    "p_z_t:0.23 0.39 0.33 0.31 1.1 0.34 1.2 0.14\n",
    "lambdaRef: 4.5e3\n",
    "sed_fmt: txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the training and target photometric catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section if for simulating a photometric catalogue from the templates. \n",
    "\n",
    "- catalog files (trainingFile, targetFile) will be created, and have the adequate format for the later stages. \n",
    "- noiseLevel describes the relative error for the absolute flux in each band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile_txt += \"\"\"\n",
    "[Simulation]\n",
    "numObjects: 1000\n",
    "noiseLevel: 0.03\n",
    "trainingFile: ./data_nb/galaxies-fluxredshifts.txt\n",
    "targetFile: ./data_nb/galaxies-fluxredshifts2.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config for the simulation of the training catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now describe the training file.\n",
    "\n",
    "- `catFile` is the input catalog. This should be a tab or space separated file with numBands + 1 columns.\n",
    "\n",
    "- `bandOrder` describes the ordering of the bands in the file. Underscore `_` means an ignored column, for example a band that shouldn't be used. The band names must correspond to those in the filter section.\n",
    "\n",
    "- `redshift` is for the photometric redshift. `referenceBand` is the reference band for normalizing the fluxes and luminosities. `extraFracFluxError` is an extra relative error to add in quadrature to the flux errors.\n",
    "\n",
    "- `paramFile` will contain the output of the GP applied to the training galaxies, i.e. the minimal parameters that must be stored in order to reconstruct the fit of each GP.\n",
    "\n",
    "- `crossValidate` is a flag for performing optional cross-validation. If so, `CVfile` will contain cross-validation data. `crossValidationBandOrder` is similar to `bandOrder` and describes the bands to be used for cross-validation. In this example I have left the R band out of `bandOrder` and put it in `crossValidationBandOrder`. However, this feature won't work on simulated data, only on real data (i.e., the `simulateWithSEDs` script below does not generate cross-validation bands).\n",
    "\n",
    "- `numChunks` is the number of chunks to split the training data into. At present please stick to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile_txt += \"\"\"\n",
    "[Training]\n",
    "catFile: ./data_nb/galaxies-fluxredshifts.txt\n",
    "bandOrder: U_SDSS U_SDSS_var G_SDSS G_SDSS_var _ _ I_SDSS I_SDSS_var Z_SDSS Z_SDSS_var redshift\n",
    "referenceBand: I_SDSS\n",
    "extraFracFluxError: 1e-4\n",
    "paramFile: ./data_nb/galaxies-gpparams.txt\n",
    "crossValidate: False\n",
    "CVfile: ./data_nb/galaxies-gpCV.txt\n",
    "crossValidationBandOrder: _ _ _ _ R_SDSS R_SDSS_var _ _ _ _ _\n",
    "numChunks: 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config for the simulation of the target catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section of the target catalog has very similar structure and parameters. The `catFile`, `bandOrder`, `referenceBand`, and `extraFracFluxError` have the same meaning as for the training, but of course don't have to be the same.\n",
    "\n",
    "`redshiftpdfFile` and `redshiftpdfFileTemp` will contain tabulated redshift posterior PDFs for the delight-apply and templateFitting scripts. \n",
    "\n",
    "Similarly, `metricsFile` and `metricsFileTemp` will contain metrics calculated from the PDFs, like mean, mode, etc. This is particularly informative if `redshift` is also provided in the target set.\n",
    "\n",
    "The compression mode can be activated with `useCompression` and will produce new redshift PDFs in the file `redshiftpdfFileComp`, while `compressIndicesFile` and `compressMargLikFile` will contain the indices and marginalized likelihood for the objects that were kept during compression. The number of objects is controled with `Ncompress`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile_txt += \"\"\"\n",
    "[Target]\n",
    "catFile: ./data_nb/galaxies-fluxredshifts2.txt\n",
    "bandOrder: U_SDSS U_SDSS_var G_SDSS G_SDSS_var _ _ I_SDSS I_SDSS_var Z_SDSS Z_SDSS_var redshift\n",
    "referenceBand: I_SDSS\n",
    "extraFracFluxError: 1e-4\n",
    "redshiftpdfFile: ./data_nb/galaxies-redshiftpdfs.txt\n",
    "redshiftpdfFileTemp: ./data_nb/galaxies-redshiftpdfs-cww.txt\n",
    "metricsFile:  ./data_nb/galaxies-redshiftmetrics.txt\n",
    "metricsFileTemp:  ./data_nb/galaxies-redshiftmetrics-cww.txt\n",
    "useCompression: False\n",
    "Ncompress: 10\n",
    "compressIndicesFile: ./data_nb/galaxies-compressionIndices.txt\n",
    "compressMargLikFile: ./data_nb/galaxies-compressionMargLikes.txt\n",
    "redshiftpdfFileComp: ./data_nb/galaxies-redshiftpdfs-comp.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the hyper-parameters of the Gaussian Process fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there are various other parameters related to the method itself.\n",
    "\n",
    "The (hyper)parameters of the Gaussian process are `zPriorSigma`, `ellPriorSigma` (locality of the model predictions in redshift and luminosity), `fluxLuminosityNorm` (some normalization parameter), `alpha_C`, `alpha_L`, `V_C`, `V_L` (smoothness and variance of the latent SED model), `lines_pos`, `lines_width` (positions and widths of the lines in the latent SED model). \n",
    "\n",
    "`redshiftMin`, `redshiftMax`, and `redshiftBinSize` describe the linear fine redshift grid to compute PDFs on.\n",
    "\n",
    "`redshiftNumBinsGPpred` describes the granuality (in log scale!) for the GP kernel to be exactly calculated on; it will then be interpolated on the finer grid.\n",
    "\n",
    "`redshiftDisBinSize` is the binsize for a tomographic redshift binning.\n",
    "\n",
    "`confidenceLevels` are the confidence levels to compute in the redshift PDF metrics.\n",
    "\n",
    "The values below should be a good default set for all of those parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramfile_txt += \"\"\"\n",
    "[Other]\n",
    "rootDir: ./\n",
    "zPriorSigma: 0.2\n",
    "ellPriorSigma: 0.5\n",
    "fluxLuminosityNorm: 1.0\n",
    "alpha_C: 1.0e3\n",
    "V_C: 0.1\n",
    "alpha_L: 1.0e2\n",
    "V_L: 0.1\n",
    "lines_pos: 6500 5002.26 3732.22\n",
    "lines_width: 20.0 20.0 20.0\n",
    "redshiftMin: 0.1\n",
    "redshiftMax: 1.101\n",
    "redshiftNumBinsGPpred: 100\n",
    "redshiftBinSize: 0.001\n",
    "redshiftDisBinSize: 0.2\n",
    "confidenceLevels: 0.1 0.50 0.68 0.95\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write this to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open('./tests_nb/parametersTest.cfg','w') as out:\n",
    "    out.write(paramfile_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l -t ./tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Delight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the filters and templates, and create a mock catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must fit the band filters with a gaussian mixture. \n",
    "This is done with this script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%run ../../scripts/processFilters.py ./tests_nb/parametersTest.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we will process the library of SEDs and project them onto the filters,\n",
    "(for the mean fct of the GP) with the following script (which may take a few minutes depending on the settings you set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%run ../../scripts/processSEDs.py tests_nb/parametersTest.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we will make some mock data with those filters and SEDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%run ../../scripts/simulateWithSEDs.py tests_nb/parametersTest.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and apply\n",
    "Run the scripts below. There should be a little bit of feedback as it is going through the lines.\n",
    "For up to 1e4 objects it should only take a few minutes max, depending on the settings above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%run ../../scripts/templateFitting.py tests_nb/parametersTest.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%run ../../scripts/delight-learn.py tests_nb/parametersTest.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%run ../../scripts/delight-apply.py tests_nb/parametersTest.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First read a bunch of useful stuff from the parameter file.\n",
    "params = parseParamFile('tests_nb/parametersTest.cfg', verbose=False)\n",
    "bandCoefAmplitudes, bandCoefPositions, bandCoefWidths, norms\\\n",
    "    = readBandCoefficients(params)\n",
    "bandNames = params['bandNames']\n",
    "numBands, numCoefs = bandCoefAmplitudes.shape\n",
    "fluxredshifts = np.loadtxt(params['target_catFile'])\n",
    "fluxredshifts_train = np.loadtxt(params['training_catFile'])\n",
    "bandIndices, bandNames, bandColumns, bandVarColumns, redshiftColumn,\\\n",
    "            refBandColumn = readColumnPositions(params, prefix='target_')\n",
    "redshiftDistGrid, redshiftGrid, redshiftGridGP = createGrids(params)\n",
    "dir_seds = params['templates_directory']\n",
    "dir_filters = params['bands_directory']\n",
    "lambdaRef = params['lambdaRef']\n",
    "sed_names = params['templates_names']\n",
    "nt = len(sed_names)\n",
    "f_mod = np.zeros((redshiftGrid.size, nt, len(params['bandNames'])))\n",
    "for t, sed_name in enumerate(sed_names):\n",
    "    f_mod[:, t, :] = np.loadtxt(dir_seds + '/' + sed_name + '_fluxredshiftmod.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the PDF files\n",
    "metricscww = np.loadtxt(params['metricsFile'])\n",
    "metrics = np.loadtxt(params['metricsFileTemp'])\n",
    "# Those of the indices of the true, mean, stdev, map, and map_std redshifts.\n",
    "i_zt, i_zm, i_std_zm, i_zmap, i_std_zmap = 0, 1, 2, 3, 4\n",
    "i_ze = i_zm\n",
    "i_std_ze = i_std_zm\n",
    "\n",
    "pdfs = np.loadtxt(params['redshiftpdfFile'])\n",
    "pdfs_cww = np.loadtxt(params['redshiftpdfFileTemp'])\n",
    "pdfatZ_cww = metricscww[:, 5] / pdfs_cww.max(axis=1)\n",
    "pdfatZ = metrics[:, 5] / pdfs.max(axis=1)\n",
    "nobj = pdfatZ.size\n",
    "#pdfs /= pdfs.max(axis=1)[:, None]\n",
    "#pdfs_cww /= pdfs_cww.max(axis=1)[:, None]\n",
    "pdfs /= np.trapz(pdfs, x=redshiftGrid, axis=1)[:, None]\n",
    "pdfs_cww /= np.trapz(pdfs_cww, x=redshiftGrid, axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ncol = 4\n",
    "fig, axs = plt.subplots(5, ncol, figsize=(7, 6), sharex=True, sharey=False)\n",
    "axs = axs.ravel()\n",
    "z = fluxredshifts[:, redshiftColumn]\n",
    "sel = np.random.choice(nobj, axs.size, replace=False)\n",
    "lw = 2\n",
    "for ik in range(axs.size):\n",
    "    k = sel[ik]\n",
    "    print(k, end=\" \")\n",
    "    axs[ik].plot(redshiftGrid, pdfs_cww[k, :],lw=lw, label='Standard template fitting')# c=\"#2ecc71\", \n",
    "    axs[ik].plot(redshiftGrid, pdfs[k, :], lw=lw, label='New method')  #, c=\"#3498db\"\n",
    "    axs[ik].axvline(fluxredshifts[k, redshiftColumn], c=\"k\", lw=1, label=r'Spec-$z$')\n",
    "    ymax = np.max(np.concatenate((pdfs[k, :], pdfs_cww[k, :])))\n",
    "    axs[ik].set_ylim([0, ymax*1.2])\n",
    "    axs[ik].set_xlim([0, 1.1])\n",
    "    axs[ik].set_yticks([])\n",
    "    axs[ik].set_xticks([0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4])\n",
    "for i in range(ncol):\n",
    "    axs[-i-1].set_xlabel('Redshift', fontsize=10)\n",
    "axs[0].legend(ncol=3, frameon=False, loc='upper left', bbox_to_anchor=(0.0, 1.4))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.1, top=0.96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "zmax = 1.5\n",
    "rr = [[0, zmax], [0, zmax]]\n",
    "nbins = 30\n",
    "h = axs[0, 0].hist2d(metricscww[:, i_zt], metricscww[:, i_zm], nbins, cmap='Greys', range=rr)\n",
    "hmin, hmax = np.min(h[0]), np.max(h[0])\n",
    "axs[0, 0].set_title('CWW z mean')\n",
    "axs[0, 1].hist2d(metricscww[:, i_zt], metricscww[:, i_zmap], nbins, cmap='Greys', range=rr, vmax=hmax)\n",
    "axs[0, 1].set_title('CWW z map')\n",
    "axs[1, 0].hist2d(metrics[:, i_zt], metrics[:, i_zm], nbins, cmap='Greys', range=rr, vmax=hmax)\n",
    "axs[1, 0].set_title('GP z mean')\n",
    "axs[1, 1].hist2d(metrics[:, i_zt], metrics[:, i_zmap], nbins, cmap='Greys', range=rr, vmax=hmax)\n",
    "axs[1, 1].set_title('GP z map')\n",
    "axs[0, 0].plot([0, zmax], [0, zmax], c='k')\n",
    "axs[0, 1].plot([0, zmax], [0, zmax], c='k')\n",
    "axs[1, 0].plot([0, zmax], [0, zmax], c='k')\n",
    "axs[1, 1].plot([0, zmax], [0, zmax], c='k')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(7, 3.5))\n",
    "chi2s = ((metrics[:, i_zt] - metrics[:, i_ze])/metrics[:, i_std_ze])**2\n",
    "\n",
    "axs[0].errorbar(metrics[:, i_zt], metrics[:, i_ze], yerr=metrics[:, i_std_ze], fmt='o', markersize=5, capsize=0)\n",
    "axs[1].errorbar(metricscww[:, i_zt], metricscww[:, i_ze], yerr=metricscww[:, i_std_ze], fmt='o', markersize=5, capsize=0)\n",
    "axs[0].plot([0, zmax], [0, zmax], 'k')\n",
    "axs[1].plot([0, zmax], [0, zmax], 'k')\n",
    "axs[0].set_xlim([0, zmax])\n",
    "axs[1].set_xlim([0, zmax])\n",
    "axs[0].set_ylim([0, zmax])\n",
    "axs[1].set_ylim([0, zmax])\n",
    "axs[0].set_title('New method')\n",
    "axs[1].set_title('Standard template fitting')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cmap = \"coolwarm_r\"\n",
    "vmin = 0.0\n",
    "alpha = 0.9\n",
    "s = 5\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3.5))\n",
    "vs = axs[0].scatter(metricscww[:, i_zt], metricscww[:, i_zmap], \n",
    "                    s=s, c=pdfatZ_cww, cmap=cmap, linewidth=0, vmin=vmin, alpha=alpha)\n",
    "vs = axs[1].scatter(metrics[:, i_zt], metrics[:, i_zmap], \n",
    "                    s=s, c=pdfatZ, cmap=cmap, linewidth=0, vmin=vmin, alpha=alpha)\n",
    "clb = plt.colorbar(vs, ax=axs.ravel().tolist())\n",
    "clb.set_label('Normalized probability at spec-$z$')\n",
    "for i in range(2):\n",
    "    axs[i].plot([0, zmax], [0, zmax], c='k', lw=1, zorder=0, alpha=1)\n",
    "    axs[i].set_ylim([0, zmax])\n",
    "    axs[i].set_xlim([0, zmax])\n",
    "    axs[i].set_xlabel('Spec-$z$')\n",
    "axs[0].set_ylabel('MAP photo-$z$')\n",
    "\n",
    "axs[0].set_title('Standard template fitting')\n",
    "axs[1].set_title('New method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Don't be too harsh with the results of the standard template fitting or the new methods since both have a lot of parameters which can be optimized!\n",
    "\n",
    "If the results above made sense, i.e. the redshifts are reasonnable for both methods on the mock data, then you can start modifying the parameter files and creating catalog files containing actual data! I recommend using less than 20k galaxies for training, and 1000 or 10k galaxies for the delight-apply script at the moment. Future updates will address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py311_rail",
   "language": "python",
   "name": "py311_rail"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
